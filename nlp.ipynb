{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the jsonl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_jsonl(filename):\n",
    "    sentences = []\n",
    "    with open(filename,  encoding=\"utf8\") as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        sentences.append(result)\n",
    "    \n",
    "    return pd.DataFrame(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open_jsonl('../train.jsonl')\n",
    "test = open_jsonl('../test.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate data between the text sentences and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text']\n",
    "y = train['lang']\n",
    "\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert text to token using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "# cv = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train_counts = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([cv.vocabulary_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model (Multinomial Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "# clf = make_pipeline(StandardScaler(with_mean = False), SVC(gamma='auto'))\n",
    "# clf.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X_train_tfidf, y_train, cv=5, scoring='f1_macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98885772, 0.9886649 , 0.98846945, 0.98959646, 0.98944482])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9f/h2ln253n6q3f0x8vpp8vfv2r0000gn/T/ipykernel_27994/3673909453.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_new_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \"\"\"\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "test_sentences = X_test\n",
    "X_new_counts = cv.transform(test_sentences)\n",
    "X_new_tfidf = tfidf.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          af       0.99      1.00      1.00      3936\n",
      "          az       0.99      1.00      0.99      3933\n",
      "          bg       1.00      1.00      1.00      4016\n",
      "          cs       0.99      1.00      1.00      3995\n",
      "          da       0.99      1.00      1.00      3983\n",
      "          de       0.99      1.00      1.00      3977\n",
      "          el       1.00      1.00      1.00      3979\n",
      "          en       0.89      1.00      0.94      4020\n",
      "          es       0.99      1.00      1.00      3977\n",
      "          fi       0.99      1.00      0.99      4039\n",
      "          fr       0.86      1.00      0.92      3927\n",
      "          hr       1.00      1.00      1.00      4028\n",
      "          it       1.00      1.00      1.00      4055\n",
      "          ko       1.00      1.00      1.00      4036\n",
      "          nl       1.00      1.00      1.00      3970\n",
      "          no       1.00      1.00      1.00      4016\n",
      "          pl       1.00      1.00      1.00      3968\n",
      "          ru       1.00      1.00      1.00      4044\n",
      "          ur       1.00      1.00      1.00      4075\n",
      "          zh       1.00      0.66      0.80      4026\n",
      "\n",
      "    accuracy                           0.98     80000\n",
      "   macro avg       0.98      0.98      0.98     80000\n",
      "weighted avg       0.98      0.98      0.98     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predicted, target_names=np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using the test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['text']\n",
    "\n",
    "X_new_counts = cv.transform(X_test)\n",
    "X_new_tfidf = tfidf.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Численность населения агломерации Парижа в 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Наиболее выдающийся вклад в создание современн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>С началом франко-прусской войны 1870—1871 годо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Основное преимущество офсетных антенн в том, ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Выручка от реализации продукции, товаров, рабо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0  Численность населения агломерации Парижа в 201...\n",
       "1   1  Наиболее выдающийся вклад в создание современн...\n",
       "2   2  С началом франко-прусской войны 1870—1871 годо...\n",
       "3   3  Основное преимущество офсетных антенн в том, ч...\n",
       "4   4  Выручка от реализации продукции, товаров, рабо..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99133</th>\n",
       "      <td>99133</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99134</th>\n",
       "      <td>99134</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99135</th>\n",
       "      <td>99135</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99136</th>\n",
       "      <td>99136</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>99137</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id lang\n",
       "0          0   ru\n",
       "1          1   ru\n",
       "2          2   ru\n",
       "3          3   ru\n",
       "4          4   ru\n",
       "...      ...  ...\n",
       "99133  99133   da\n",
       "99134  99134   da\n",
       "99135  99135   da\n",
       "99136  99136   da\n",
       "99137  99137   da\n",
       "\n",
       "[99138 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_new = pd.concat([test.text, pd.DataFrame(predicted, columns=['predicted'])], axis=1)\n",
    "df_new = pd.concat([test.id, pd.DataFrame(predicted, columns=['lang'])], axis=1)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_json('predictions.jsonl', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Orbitoproetus',\n",
       " 'Ormistoniella',\n",
       " 'Osmolskia',\n",
       " 'Paladin',\n",
       " 'Palpebralina',\n",
       " 'Panibole',\n",
       " 'Paraglobusia',\n",
       " 'Paraproetus',\n",
       " 'Parvidumus',\n",
       " 'Pedinocoryphe',\n",
       " 'Pedinodechenella',\n",
       " 'Perexigupyge',\n",
       " 'Phillibole',\n",
       " 'Phillibolina',\n",
       " 'Philliboloides',\n",
       " 'Phillipsia',\n",
       " 'Piltonia',\n",
       " 'Plesiowensus',\n",
       " 'Podoliproetus',\n",
       " 'Praedechenella',\n",
       " 'Pragoproetus',\n",
       " 'Prantlia',\n",
       " 'Proetidellinae',\n",
       " 'Proetiella',\n",
       " 'Proetinae',\n",
       " 'Proetus',\n",
       " 'Pseudodechenella',\n",
       " 'Pseudodudu',\n",
       " 'Pseudoproetus',\n",
       " 'Pseudospatulina',\n",
       " 'Pseudowaribole',\n",
       " 'Pudoproetus',\n",
       " 'Reediella',\n",
       " 'Rhenogriffides',\n",
       " 'Richterella',\n",
       " 'Ryckholtia',\n",
       " 'Schaderthalaspis',\n",
       " 'Schizoproetina',\n",
       " 'Schizoproetoides',\n",
       " 'Schizoproetus',\n",
       " 'Semiproetus',\n",
       " 'Sevillia',\n",
       " 'Silesiops',\n",
       " 'Simaproetus',\n",
       " 'Spinibole',\n",
       " 'Spinibolops',\n",
       " 'Tawstockia',\n",
       " 'Tetinia',\n",
       " 'Thebanaspis',\n",
       " 'Thigriffides',\n",
       " 'Tropidocare',\n",
       " 'Tropidocoryphinae',\n",
       " 'Typhloproetus',\n",
       " 'Unguliproetus',\n",
       " 'Warburgellinae',\n",
       " 'Waribole',\n",
       " 'Weberides',\n",
       " 'Weyeraspis',\n",
       " 'Winiskia',\n",
       " 'Winterbergia',\n",
       " 'Witryides',\n",
       " 'Xenadoche',\n",
       " 'Xenocybe']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape\n",
    "df_new[df_new.predicted=='zh']\n",
    "weird = df_new.iloc[76104].text.split(', ')\n",
    "weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paladin\n",
      "Sevillia\n"
     ]
    }
   ],
   "source": [
    "for w in weird:\n",
    "    if train[train.text.str.contains(w)].shape[0] > 0:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70516</th>\n",
       "      <td>70516</td>\n",
       "      <td>el</td>\n",
       "      <td>Το όγδοο άλμπουμ των HammerFall που κυκλοφόρησ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92564</th>\n",
       "      <td>92564</td>\n",
       "      <td>es</td>\n",
       "      <td>Gastón II, apodado el Paladino, fue conde de F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119396</th>\n",
       "      <td>119396</td>\n",
       "      <td>zh</td>\n",
       "      <td>作為作品的主要敵人,被描述為最弱小的怪物,擁有孩童般的智力與力量,但懂得使用武器與集團行動的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147223</th>\n",
       "      <td>147223</td>\n",
       "      <td>it</td>\n",
       "      <td>L'edizione italiana è curata da Ludovica Bonan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149073</th>\n",
       "      <td>149073</td>\n",
       "      <td>it</td>\n",
       "      <td>Nel 1351 Raffaele Maremonti ebbe l'investitura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223813</th>\n",
       "      <td>223813</td>\n",
       "      <td>no</td>\n",
       "      <td>I 1852 ble jernbanen \"Compagnies ferroviaires ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256137</th>\n",
       "      <td>256137</td>\n",
       "      <td>de</td>\n",
       "      <td>\"Hero's Quest\" bzw. \"Quest for Glory I\" wird ü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297515</th>\n",
       "      <td>297515</td>\n",
       "      <td>en</td>\n",
       "      <td>During the late 1970s in the United States pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319911</th>\n",
       "      <td>319911</td>\n",
       "      <td>hr</td>\n",
       "      <td>Videospot za pjesmu je objavljen 23. svibnja 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339516</th>\n",
       "      <td>339516</td>\n",
       "      <td>fr</td>\n",
       "      <td>La seule exploitation minière à grande échelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388365</th>\n",
       "      <td>388365</td>\n",
       "      <td>da</td>\n",
       "      <td>Senere arbejdede han med fuldt udviklet turbul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id lang                                               text\n",
       "70516    70516   el  Το όγδοο άλμπουμ των HammerFall που κυκλοφόρησ...\n",
       "92564    92564   es  Gastón II, apodado el Paladino, fue conde de F...\n",
       "119396  119396   zh  作為作品的主要敵人,被描述為最弱小的怪物,擁有孩童般的智力與力量,但懂得使用武器與集團行動的...\n",
       "147223  147223   it  L'edizione italiana è curata da Ludovica Bonan...\n",
       "149073  149073   it  Nel 1351 Raffaele Maremonti ebbe l'investitura...\n",
       "223813  223813   no  I 1852 ble jernbanen \"Compagnies ferroviaires ...\n",
       "256137  256137   de  \"Hero's Quest\" bzw. \"Quest for Glory I\" wird ü...\n",
       "297515  297515   en  During the late 1970s in the United States pai...\n",
       "319911  319911   hr  Videospot za pjesmu je objavljen 23. svibnja 2...\n",
       "339516  339516   fr  La seule exploitation minière à grande échelle...\n",
       "388365  388365   da  Senere arbejdede han med fuldt udviklet turbul..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.text.str.contains('Paladin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'作為作品的主要敵人,被描述為最弱小的怪物,擁有孩童般的智力與力量,但懂得使用武器與集團行動的特性讓牠們在狹小場所如洞窟內深具威脅,是新人冒險者的主要對手。擁有較高的資質、長期累積經驗並且生存的哥布林,能夠成長為不同的亞種:鄉巴佬(Hob)、薩滿(Shaman)、英雄(Champion)、王(Lord),甚至是聖騎士(Paladin)與龍騎士(Dragoon)。作品中並未出現過哥布林的母體,哥布林透過搶奪類人生物(人類、精靈、矮人、半身人等)的女性為牠們延續後代。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[119396].text"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "535e7dfa4e79b8a16ee5958c03c29abfca9eab7a4cbaa00a7baba8beca86875c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
